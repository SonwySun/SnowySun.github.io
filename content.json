{"meta":{"title":"title","subtitle":"subtitle","description":"description","author":"author","url":"http://qingxi220.cn","root":"/"},"pages":[{"title":"关于","date":"2019-12-25T06:09:15.092Z","updated":"2019-12-24T15:59:57.000Z","comments":false,"path":"about/index.html","permalink":"http://qingxi220.cn/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"标签","date":"2019-12-25T06:10:06.004Z","updated":"2019-12-24T15:59:57.000Z","comments":false,"path":"tags/index.html","permalink":"http://qingxi220.cn/tags/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2019-12-25T03:58:34.671Z","updated":"2019-12-24T15:59:57.000Z","comments":false,"path":"repository/index.html","permalink":"http://qingxi220.cn/repository/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-12-25T06:21:24.657Z","updated":"2019-12-24T15:59:57.000Z","comments":false,"path":"categories/index.html","permalink":"http://qingxi220.cn/categories/index.html","excerpt":"","text":""},{"title":"404 Not Found：该页无法显示","date":"2019-12-25T06:20:34.768Z","updated":"2019-12-24T15:59:57.000Z","comments":false,"path":"/404.html","permalink":"http://qingxi220.cn/404.html","excerpt":"","text":""}],"posts":[{"title":"【算法】一文带你梳理机器学习经典算法","slug":"ClassicMLAlgorithms","date":"2019-12-25T13:29:30.000Z","updated":"2019-12-25T14:20:51.513Z","comments":true,"path":"2019/12/25/ClassicMLAlgorithms/","link":"","permalink":"http://qingxi220.cn/2019/12/25/ClassicMLAlgorithms/","excerpt":"","text":"1. KNN2. 朴素贝叶斯3. 决策树决策树可以理解为构造一棵树状结构的筛选”管道”，使得样本经过逐层的筛选后，最终落到叶子节点的样本有最高的纯净度。这里筛选是对样本的n维特征进行筛选。 决策树算法中涉及到的基础理论有信息论中的信息熵。 信息熵公式的思想 1. 事件A的信息量的大小跟事件A出现的概率成反比的关系 ps：这里有公式回头补上 2. 当两个事件独立时，两个事件的信息量应该等于两个事件各自信息量相加的和 ps：这里有公式回头补上 3. 信息量的函数应该大于等于0 得出信息量函数 information function Entropy 信息熵是信息量的期望 ps：这里有公式回头补上 Information Gain 信息增益 ps：这里有公式回头补上如何分割决策树的节点","categories":[{"name":"机器学习算法","slug":"机器学习算法","permalink":"http://qingxi220.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://qingxi220.cn/tags/Machine-Learning/"}]},{"title":"【资料】机器学习参考资料整理","slug":"MachineLearningReferences","date":"2019-12-25T13:00:27.000Z","updated":"2019-12-25T14:12:48.129Z","comments":true,"path":"2019/12/25/MachineLearningReferences/","link":"","permalink":"http://qingxi220.cn/2019/12/25/MachineLearningReferences/","excerpt":"","text":"1. Mitchell, T.M. (1997) Machine Learning非常早的一本介绍机器学习领域核心概念和基本算法的经典书籍之一","categories":[{"name":"资料","slug":"资料","permalink":"http://qingxi220.cn/categories/%E8%B5%84%E6%96%99/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://qingxi220.cn/tags/Machine-Learning/"}]},{"title":"【算法】关系网络在金融风控中的应用系列（一）——社区分割louvain算法","slug":"IntroductionOfLouvain","date":"2019-12-25T07:58:14.000Z","updated":"2019-12-25T13:13:00.776Z","comments":true,"path":"2019/12/25/IntroductionOfLouvain/","link":"","permalink":"http://qingxi220.cn/2019/12/25/IntroductionOfLouvain/","excerpt":"","text":"","categories":[{"name":"图算法","slug":"图算法","permalink":"http://qingxi220.cn/categories/%E5%9B%BE%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"spark-graphx","slug":"spark-graphx","permalink":"http://qingxi220.cn/tags/spark-graphx/"},{"name":"scala","slug":"scala","permalink":"http://qingxi220.cn/tags/scala/"}]},{"title":"开篇","slug":"FirstBlog","date":"2019-12-25T06:45:47.000Z","updated":"2019-12-25T08:07:07.176Z","comments":true,"path":"2019/12/25/FirstBlog/","link":"","permalink":"http://qingxi220.cn/2019/12/25/FirstBlog/","excerpt":"","text":"工作五年了，反思自己积累甚少，对职龄的恐惧却与日俱增。 废话不多说啦，2020年开始坚持写博客，相信种一棵树最好的时间就是现在。","categories":[],"tags":[]}]}